#!/bin/bash
# docker-entrypoint.sh
# Startup script for CodedSwitch with Ollama

set -e

echo "üöÄ Starting CodedSwitch with Local AI..."

# Start Ollama in background
echo "üñ•Ô∏è Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to be ready with health check loop
echo "‚è≥ Waiting for Ollama to be ready..."
MAX_RETRIES=30
RETRY_COUNT=0

while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "‚úÖ Ollama is ready!"
        break
    fi
    RETRY_COUNT=$((RETRY_COUNT + 1))
    echo "   Waiting for Ollama... ($RETRY_COUNT/$MAX_RETRIES)"
    sleep 2
done

if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
    echo "‚ö†Ô∏è Ollama did not start in time, continuing anyway (will use cloud fallback)"
fi

# Verify model is available
echo "üì¶ Verifying Phi3 model..."
if ollama list 2>/dev/null | grep -q "phi3:medium"; then
    echo "‚úÖ Phi3 model is ready"
else
    echo "‚ö†Ô∏è Model not found. Starting download in background (server will start now; cloud fallback will be used until model is ready)..."
    (
      set +e
      ollama pull phi3:medium
      if [ $? -eq 0 ]; then
        echo "‚úÖ Phi3 model downloaded"
      else
        echo "‚ö†Ô∏è Phi3 model download failed; cloud fallback will remain in use"
      fi
    ) &
fi

# Start CodedSwitch
echo "üéµ Starting CodedSwitch server..."
exec node dist/index.cjs
